{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10522249,
          "sourceType": "datasetVersion",
          "datasetId": 6512220
        },
        {
          "sourceId": 10707794,
          "sourceType": "datasetVersion",
          "datasetId": 6636181
        }
      ],
      "dockerImageVersionId": 30886,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 24.527731,
      "end_time": "2025-02-02T19:36:08.963217",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-02-02T19:35:44.435486",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "1a2f1ac6",
      "cell_type": "code",
      "source": [
        "# Importing necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 3.755162,
          "end_time": "2025-02-02T19:35:51.771160",
          "exception": false,
          "start_time": "2025-02-02T19:35:48.015998",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:13.143365Z",
          "iopub.execute_input": "2025-02-17T05:58:13.143691Z",
          "iopub.status.idle": "2025-02-17T05:58:14.190443Z",
          "shell.execute_reply.started": "2025-02-17T05:58:13.143662Z",
          "shell.execute_reply": "2025-02-17T05:58:14.189532Z"
        },
        "id": "1a2f1ac6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "139015f7",
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets from Colab's default upload directory\n",
        "detection_train = pd.read_csv('/content/Dataset.csv').dropna(axis=1)\n",
        "class_train = pd.read_csv('/content/Dataset_2.csv').dropna(axis=1)\n",
        "\n",
        "features=['Va','Vb','Vc','Ia','Ib','Ic']\n",
        "class_target = ['G','C','B','A']"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.110467,
          "end_time": "2025-02-02T19:35:51.888157",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.777690",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:18.340369Z",
          "iopub.execute_input": "2025-02-17T05:58:18.340822Z",
          "iopub.status.idle": "2025-02-17T05:58:18.420993Z",
          "shell.execute_reply.started": "2025-02-17T05:58:18.340792Z",
          "shell.execute_reply": "2025-02-17T05:58:18.420345Z"
        },
        "id": "139015f7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "44924cd7",
      "cell_type": "code",
      "source": [
        "  #Defining the inputs and outputs\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['l']\n",
        "class_data_Y = class_train[class_target]"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.034634,
          "end_time": "2025-02-02T19:35:51.929702",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.895068",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:22.521172Z",
          "iopub.execute_input": "2025-02-17T05:58:22.521446Z",
          "iopub.status.idle": "2025-02-17T05:58:22.536351Z",
          "shell.execute_reply.started": "2025-02-17T05:58:22.521427Z",
          "shell.execute_reply": "2025-02-17T05:58:22.535420Z"
        },
        "id": "44924cd7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "27697e9c",
      "cell_type": "code",
      "source": [
        "#Defining accuracy and error vectors\n",
        "detect_accuracy = list()\n",
        "detect_error = list()\n",
        "class_accuracy = list()\n",
        "class_error = list()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011979,
          "end_time": "2025-02-02T19:35:51.948235",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.936256",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:25.495028Z",
          "iopub.execute_input": "2025-02-17T05:58:25.495306Z",
          "iopub.status.idle": "2025-02-17T05:58:25.499170Z",
          "shell.execute_reply.started": "2025-02-17T05:58:25.495287Z",
          "shell.execute_reply": "2025-02-17T05:58:25.498393Z"
        },
        "id": "27697e9c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "de605133",
      "cell_type": "code",
      "source": [
        "#Splitting the data\n",
        "class_train_X,class_test_X,class_train_Y,class_test_Y= train_test_split(class_data_X,class_data_Y,test_size=0.33,random_state=1)\n",
        "detection_train_X,detection_test_X,detection_train_Y,detection_test_Y = train_test_split(detection_data_X,detection_data_Y,test_size=0.33,random_state=1)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.015772,
          "end_time": "2025-02-02T19:35:51.970239",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.954467",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:28.840321Z",
          "iopub.execute_input": "2025-02-17T05:58:28.840623Z",
          "iopub.status.idle": "2025-02-17T05:58:28.849665Z",
          "shell.execute_reply.started": "2025-02-17T05:58:28.840599Z",
          "shell.execute_reply": "2025-02-17T05:58:28.848928Z"
        },
        "id": "de605133"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RBN**"
      ],
      "metadata": {
        "id": "BOqPLHwse0n9"
      },
      "id": "BOqPLHwse0n9"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ===================== ✅ CHECK DATA SHAPES ✅ ===================== #\n",
        "\n",
        "print(f\"detection_data_X shape: {detection_data_X.shape}\")\n",
        "print(f\"detection_data_Y shape: {detection_data_Y.shape}\")\n",
        "\n",
        "print(f\"class_data_X shape: {class_data_X.shape}\")\n",
        "print(f\"class_data_Y shape: {class_data_Y.shape}\")\n",
        "\n",
        "# ✅ Ensure Features (X) and Labels (Y) have the SAME number of samples\n",
        "assert detection_data_X.shape[0] == detection_data_Y.shape[0], \"❌ Mismatch in Detection Dataset!\"\n",
        "assert class_data_X.shape[0] == class_data_Y.shape[0], \"❌ Mismatch in Classification Dataset!\"\n",
        "\n",
        "# ✅ Convert Multi-Column Target (Y) to 1D Array\n",
        "if isinstance(detection_data_Y, pd.DataFrame) and detection_data_Y.shape[1] > 1:\n",
        "    detection_data_Y = detection_data_Y.values.argmax(axis=1)  # Convert One-Hot Encoding to Single Column\n",
        "\n",
        "if isinstance(class_data_Y, pd.DataFrame) and class_data_Y.shape[1] > 1:\n",
        "    class_data_Y = class_data_Y.values.argmax(axis=1)\n",
        "\n",
        "# ✅ Train-Test Split (Corrected)\n",
        "detection_train_X, detection_test_X, detection_train_Y, detection_test_Y = train_test_split(\n",
        "    detection_data_X, detection_data_Y, test_size=0.2, random_state=42, stratify=detection_data_Y)\n",
        "\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=42, stratify=class_data_Y)\n",
        "\n",
        "# ✅ Convert Y to 1D array\n",
        "detection_train_Y = detection_train_Y.ravel()\n",
        "detection_test_Y = detection_test_Y.ravel()\n",
        "class_train_Y = class_train_Y.ravel()\n",
        "class_test_Y = class_test_Y.ravel()\n",
        "# ===================== RBM + LOGISTIC REGRESSION FOR DETECTION ===================== #\n",
        "\n",
        "scaler = StandardScaler()\n",
        "pca_detection = PCA(n_components=min(5, detection_train_X.shape[1]))  # Prevent PCA errors\n",
        "\n",
        "rbm_detection = BernoulliRBM(n_components=128, learning_rate=0.05, n_iter=200, random_state=42)\n",
        "logistic_detection = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
        "\n",
        "rbm_detection_pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('pca', pca_detection),\n",
        "    ('rbm', rbm_detection),\n",
        "    ('logistic', logistic_detection)\n",
        "])\n",
        "\n",
        "rbm_detection_pipeline.fit(detection_train_X, detection_train_Y)\n",
        "detection_preds = rbm_detection_pipeline.predict(detection_test_X)\n",
        "\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "\n",
        "print(f\" Detection Accuracy: {detection_accuracy:.4f} | MSE: {detection_mse:.4f}\")\n",
        "\n",
        "# =====================  RBM + LOGISTIC REGRESSION FOR CLASSIFICATION ===================== #\n",
        "\n",
        "pca_classification = PCA(n_components=min(10, class_train_X.shape[1]))  # Prevent PCA errors\n",
        "\n",
        "rbm_class = BernoulliRBM(n_components=256, learning_rate=0.05, n_iter=200, random_state=42)\n",
        "logistic_class = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
        "\n",
        "rbm_class_pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('pca', pca_classification),\n",
        "    ('rbm', rbm_class),\n",
        "    ('logistic', logistic_class)\n",
        "])\n",
        "\n",
        "rbm_class_pipeline.fit(class_train_X, class_train_Y)\n",
        "class_preds = rbm_class_pipeline.predict(class_test_X)\n",
        "\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "classification_mse = mean_squared_error(class_test_Y, class_preds)\n",
        "\n",
        "print(f\"Classification Accuracy: {classification_accuracy:.4f} | MSE: {classification_mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "TcT_ekU6McUj"
      },
      "id": "TcT_ekU6McUj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBN**"
      ],
      "metadata": {
        "id": "ifVO3muwftSR"
      },
      "id": "ifVO3muwftSR"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "\n",
        "# Standardize Data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Train-Test Split (if not already split)\n",
        "detection_train_X, detection_test_X, detection_train_Y, detection_test_Y = train_test_split(\n",
        "    detection_data_X, detection_data_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing Features\n",
        "detection_train_X = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X = scaler.transform(detection_test_X)\n",
        "\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "\n",
        "# ===================== DEEP BELIEF NETWORK (DBN) FOR DETECTION ===================== #\n",
        "\n",
        "# Define Model for Detection\n",
        "model_detection = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(detection_train_X.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model_detection.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model_detection.fit(detection_train_X, detection_train_Y, epochs=70, batch_size=32, verbose=0)\n",
        "\n",
        "# Predictions\n",
        "detection_preds = (model_detection.predict(detection_test_X) > 0.5).astype(int)\n",
        "\n",
        "# Metrics\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "\n",
        "# Print Detection Model Metrics\n",
        "print(\"\\n🔹 Optimized Detection Model Performance\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Detection Model Mean Squared Error: {detection_mse:.4f}\")\n",
        "print(f\"DBN Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# ===================== DEEP BELIEF NETWORK (DBN) FOR CLASSIFICATION ===================== #\n",
        "\n",
        "# Define Model for Classification (Multi-Class)\n",
        "num_classes = len(np.unique(class_train_Y))\n",
        "\n",
        "model_class = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(class_train_X.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')  # Multi-class classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model_class.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model_class.fit(class_train_X, class_train_Y, epochs=80, batch_size=32, verbose=0)\n",
        "\n",
        "# Predictions\n",
        "class_preds = np.argmax(model_class.predict(class_test_X), axis=1)\n",
        "\n",
        "# Metrics\n",
        "classification_mse = mean_squared_error(class_test_Y, class_preds)\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "\n",
        "# Print Classification Model Metrics\n",
        "print(\"\\n🔹 Optimized Classification Model Performance\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Classification Model Mean Squared Error: {classification_mse:.4f}\")\n",
        "print(f\"DBN Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(class_test_Y, class_preds))\n"
      ],
      "metadata": {
        "id": "XQUysozoMuWp"
      },
      "id": "XQUysozoMuWp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "SKb4W3vre74O"
      },
      "id": "SKb4W3vre74O"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Add, GlobalAveragePooling1D, Dense, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Splitting Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "class_data_Y = np.argmax(class_data_Y.values, axis=1)\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.1, random_state=00)\n",
        "\n",
        "detection_train_X, detection_test_X, detection_train_Y, detection_test_Y = train_test_split(\n",
        "    detection_data_X, detection_data_Y, test_size=0.9, random_state=00)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "detection_train_X = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X = scaler.transform(detection_test_X)\n",
        "\n",
        "# Reshape for Conv1D\n",
        "class_train_X = np.expand_dims(class_train_X, axis=-1)\n",
        "class_test_X = np.expand_dims(class_test_X, axis=-1)\n",
        "detection_train_X = np.expand_dims(detection_train_X, axis=-1)\n",
        "detection_test_X = np.expand_dims(detection_test_X, axis=-1)\n",
        "\n",
        "# ===================== DATA AUGMENTATION FUNCTION ===================== #\n",
        "def augment_data(X, Y):\n",
        "    augmented_X, augmented_Y = [], []\n",
        "    for i in range(len(X)):\n",
        "        sample = X[i]\n",
        "        # Apply random noise\n",
        "        noise = np.random.normal(0, 0.02, sample.shape)\n",
        "        augmented_X.append(sample + noise)\n",
        "        augmented_Y.append(Y[i])\n",
        "    return np.array(augmented_X), np.array(augmented_Y)\n",
        "\n",
        "# Augment Training Data\n",
        "aug_X, aug_Y = augment_data(class_train_X, class_train_Y)\n",
        "class_train_X = np.concatenate((class_train_X, aug_X), axis=0)\n",
        "class_train_Y = np.concatenate((class_train_Y, aug_Y), axis=0)\n",
        "\n",
        "# ===================== RESIDUAL CNN MODEL FOR CLASSIFICATION ===================== #\n",
        "def build_classification_model():\n",
        "    inputs = Input(shape=(6, 1))\n",
        "\n",
        "    # Initial Conv Block\n",
        "    x = Conv1D(128, kernel_size=3, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual Block 1\n",
        "    res = Conv1D(128, kernel_size=3, padding='same')(x)\n",
        "    res = BatchNormalization()(res)\n",
        "    res = Activation('relu')(res)\n",
        "    res = Conv1D(128, kernel_size=3, padding='same')(res)\n",
        "    res = BatchNormalization()(res)\n",
        "\n",
        "    x = Add()([x, res])  # Skip Connection\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual Block 2\n",
        "    res = Conv1D(256, kernel_size=3, padding='same')(x)\n",
        "    res = BatchNormalization()(res)\n",
        "    res = Activation('relu')(res)\n",
        "    res = Conv1D(256, kernel_size=3, padding='same')(res)\n",
        "    res = BatchNormalization()(res)\n",
        "\n",
        "    # Projection Layer to Match Shapes\n",
        "    x = Conv1D(256, kernel_size=1, padding=\"same\")(x)  # 1x1 Conv to align shape\n",
        "    x = Add()([x, res])  # Skip Connection\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)  # Prevent overfitting\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    outputs = Dense(len(class_target), activation='softmax')(x)  # Multi-Class Output\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Build & Compile Model\n",
        "model_classification = build_classification_model()\n",
        "model_classification.compile(optimizer=AdamW(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning Rate & Early Stopping\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Train Model\n",
        "model_classification.fit(class_train_X, class_train_Y, epochs=15, batch_size=64, validation_data=(class_test_X, class_test_Y), callbacks=[lr_scheduler, early_stopping], verbose=1)\n",
        "\n",
        "# Predictions\n",
        "class_preds = np.argmax(model_classification.predict(class_test_X), axis=1)\n",
        "\n",
        "# Accuracy\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "print(f\"\\n🔹 CNN Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(class_test_Y, class_preds))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "j08ocUTXIkwI"
      },
      "id": "j08ocUTXIkwI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s-LFfKqwxDb3"
      },
      "id": "s-LFfKqwxDb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import shap\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Splitting Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=1, stratify=class_data_Y)\n",
        "\n",
        "detection_train_X, detection_test_X, detection_train_Y, detection_test_Y = train_test_split(\n",
        "    detection_data_X, detection_data_Y, test_size=0.2, random_state=1, stratify=detection_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "detection_train_X = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X = scaler.transform(detection_test_X)\n",
        "\n",
        "# ===================== DATA BALANCING WITH SMOTE ===================== #\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=1)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(class_train_X, class_train_Y)\n",
        "\n",
        "# ===================== FEATURE SELECTION USING SHAP ===================== #\n",
        "xgb_temp = xgb.XGBClassifier(n_estimators=10, random_state=42)\n",
        "xgb_temp.fit(class_train_X_smote, class_train_Y_smote)\n",
        "\n",
        "explainer = shap.Explainer(xgb_temp)\n",
        "shap_values = explainer(class_train_X_smote)\n",
        "shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "\n",
        "# Selecting top features\n",
        "top_features = np.argsort(shap_importance)[-4:]  # Select best 4 features\n",
        "class_train_X_smote = class_train_X_smote[:, top_features]\n",
        "class_test_X = class_test_X[:, top_features]\n",
        "\n",
        "# ===================== XGBOOST MODEL WITH GRID SEARCH ===================== #\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(class_target), random_state=42)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'n_estimators': [30, 40, 50],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(class_train_X_smote, class_train_Y_smote)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "# ===================== FINAL TRAINING WITH OPTIMIZED PARAMETERS ===================== #\n",
        "best_xgb.fit(class_train_X_smote, class_train_Y_smote)\n",
        "\n",
        "# Predictions\n",
        "xgb_preds = best_xgb.predict(class_test_X)\n",
        "\n",
        "# Accuracy Calculation\n",
        "xgb_accuracy = accuracy_score(class_test_Y, xgb_preds)\n",
        "print(f\"XGBoost Optimized Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# ===================== RESULT ===================== #\n",
        "if xgb_accuracy >= 0.99:\n",
        "    print(\" Achieved near-perfect accuracy!\")\n",
        "elif xgb_accuracy >= 0.95:\n",
        "    print(\"Accuracy is very high! Further tuning might be unnecessary.\")\n",
        "else:\n",
        "    print(\"⚠️ Still below 95%, consider more hyperparameter tuning.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OtnM0LvnTJTx"
      },
      "id": "OtnM0LvnTJTx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6yxfuFwTE4sm"
      },
      "id": "6yxfuFwTE4sm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dx7vNfMhGcJ_"
      },
      "id": "dx7vNfMhGcJ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Splitting Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=42, stratify=class_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "\n",
        "# ===================== DATA BALANCING WITH SMOTE ===================== #\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(class_train_X, class_train_Y)\n",
        "\n",
        "# ===================== FEATURE ENGINEERING ===================== #\n",
        "pca = PCA(n_components=4)  # Reduce dimensionality while retaining information\n",
        "class_train_X_smote = pca.fit_transform(class_train_X_smote)\n",
        "class_test_X = pca.transform(class_test_X)\n",
        "\n",
        "# ===================== BASE MODELS ===================== #\n",
        "base_models = [\n",
        "    ('xgb', XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=6, use_label_encoder=False, eval_metric='mlogloss')),\n",
        "    ('lgbm', LGBMClassifier(n_estimators=100, learning_rate=0.05, max_depth=6)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),\n",
        "    ('cat', CatBoostClassifier(iterations=200, depth=6, learning_rate=0.05, verbose=0))\n",
        "]\n",
        "\n",
        "# ===================== STACKING CLASSIFIER ===================== #\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=XGBClassifier(n_estimators=50, learning_rate=0.05, max_depth=6, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    passthrough=True  # Allow base models' predictions as features\n",
        ")\n",
        "\n",
        "# Train Stacking Model\n",
        "stacking_model.fit(class_train_X_smote, class_train_Y_smote)\n",
        "\n",
        "# Predictions\n",
        "stacking_preds = stacking_model.predict(class_test_X)\n",
        "\n",
        "# Accuracy Score\n",
        "stacking_accuracy = accuracy_score(class_test_Y, stacking_preds)\n",
        "print(f\"FINAL STACKING CLASSIFICATION ACCURACY: {stacking_accuracy:.4f}\")\n",
        "\n",
        "# ===================== CHECK ACCURACY ===================== #\n",
        "if stacking_accuracy >= 0.95:\n",
        "    print(\"Achieved 95%+ Accuracy! 🎉\")\n",
        "else:\n",
        "    print(\"⚠️ Still below 95%, consider further fine-tuning.\")\n"
      ],
      "metadata": {
        "id": "wpfy53TZESlv"
      },
      "id": "wpfy53TZESlv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EX **AI**"
      ],
      "metadata": {
        "id": "pPyj-4t7CHke"
      },
      "id": "pPyj-4t7CHke"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install interpret shap\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6-fDNFiiCjRG"
      },
      "id": "6-fDNFiiCjRG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Splitting Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=42, stratify=class_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "\n",
        "# ===================== DATA BALANCING WITH SMOTE ===================== #\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(class_train_X, class_train_Y)\n",
        "\n",
        "# ===================== XGBOOST MODEL ===================== #\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=180,  # More trees for better learning\n",
        "    learning_rate=0.03,\n",
        "    max_depth=10,  # Deeper trees for better classification\n",
        "    colsample_bytree=0.9,  # Feature selection\n",
        "    subsample=0.9,  # Sample reduction for better generalization\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(class_target),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model.fit(class_train_X_smote, class_train_Y_smote)\n",
        "\n",
        "# XGBoost Predictions\n",
        "xgb_preds = xgb_model.predict(class_test_X)\n",
        "xgb_accuracy = accuracy_score(class_test_Y, xgb_preds)\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# ===================== MULTI-LAYER PERCEPTRON (MLP) ===================== #\n",
        "def build_mlp_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(class_train_X.shape[1],)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(len(class_target), activation='softmax'))  # Multi-class output\n",
        "    return model\n",
        "\n",
        "# Compile Model\n",
        "mlp_model = build_mlp_model()\n",
        "mlp_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "mlp_model.fit(class_train_X_smote, class_train_Y_smote, epochs=50, batch_size=32, validation_data=(class_test_X, class_test_Y), verbose=1)\n",
        "\n",
        "# MLP Predictions\n",
        "mlp_preds = np.argmax(mlp_model.predict(class_test_X), axis=1)\n",
        "mlp_accuracy = accuracy_score(class_test_Y, mlp_preds)\n",
        "print(f\"MLP Accuracy: {mlp_accuracy:.4f}\")\n",
        "\n",
        "# ===================== STACKING ENSEMBLE ===================== #\n",
        "final_preds = (xgb_preds + mlp_preds) // 2  # Majority Voting\n",
        "\n",
        "# Final Accuracy\n",
        "final_accuracy = accuracy_score(class_test_Y, final_preds)\n",
        "print(f\"FINAL STACKING CLASSIFICATION ACCURACY: {final_accuracy:.4f}\")\n",
        "\n",
        "# ===================== CHECK ACCURACY ===================== #\n",
        "if final_accuracy >= 0.95:\n",
        "    print(\"✅ Achieved 95%+ Accuracy! 🎉\")\n",
        "else:\n",
        "    print(\"Still below 95%, consider more tuning.\")\n"
      ],
      "metadata": {
        "id": "zDQvZR92CFQz"
      },
      "id": "zDQvZR92CFQz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "wzGCoZX1txp_"
      },
      "id": "wzGCoZX1txp_"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Splitting Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.9, random_state=1, stratify=class_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "\n",
        "# Reshape Data for LSTM (Samples, Time Steps, Features)\n",
        "class_train_X = class_train_X.reshape((class_train_X.shape[0], 1, class_train_X.shape[1]))\n",
        "class_test_X = class_test_X.reshape((class_test_X.shape[0], 1, class_test_X.shape[1]))\n",
        "\n",
        "# ===================== DATA BALANCING WITH SMOTE ===================== #\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(\n",
        "    class_train_X.reshape(class_train_X.shape[0], -1), class_train_Y\n",
        ")\n",
        "class_train_X_smote = class_train_X_smote.reshape((class_train_X_smote.shape[0], 1, class_train_X_smote.shape[1]))\n",
        "\n",
        "# ===================== LSTM MODEL ===================== #\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu'), input_shape=(1, class_train_X.shape[2])))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=False, activation='relu')))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(len(class_target), activation='softmax'))  # Multi-class output\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile Model\n",
        "lstm_model = build_lstm_model()\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                   loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "lstm_model.fit(class_train_X_smote, class_train_Y_smote, epochs=100, batch_size=32, validation_data=(class_test_X, class_test_Y), verbose=1)\n",
        "\n",
        "# Predictions\n",
        "lstm_preds = np.argmax(lstm_model.predict(class_test_X), axis=1)\n",
        "lstm_accuracy = accuracy_score(class_test_Y, lstm_preds)\n",
        "print(f\"LSTM Classification Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "# ===================== CHECK ACCURACY ===================== #\n",
        "if lstm_accuracy >= 0.95:\n",
        "    print(\"Achieved 95%+ Accuracy! 🎉\")\n",
        "else:\n",
        "    print(\"⚠️ Still below 95%, consider deeper tuning.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WtEtFtoftyGt"
      },
      "id": "WtEtFtoftyGt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM- **DWT**"
      ],
      "metadata": {
        "id": "0Yt_LCI8zJ-6"
      },
      "id": "0Yt_LCI8zJ-6"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets\n"
      ],
      "metadata": {
        "id": "SemT3DBEzKOf"
      },
      "id": "SemT3DBEzKOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Load Data\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert One-Hot Encoding to Integer Labels\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Function to Apply DWT on Each Feature Column\n",
        "def apply_dwt(signal):\n",
        "    coeffs = pywt.wavedec(signal, 'db4', level=3)  # Using Daubechies wavelet (db4)\n",
        "    features = np.concatenate([np.ravel(c) for c in coeffs])  # Flatten coefficients\n",
        "    return features\n",
        "\n",
        "# Apply DWT Transformation\n",
        "class_data_X_dwt = np.apply_along_axis(apply_dwt, axis=1, arr=class_data_X)\n",
        "\n",
        "# Train-Test Split\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X_dwt, class_data_Y, test_size=0.2, random_state=42, stratify=class_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "\n",
        "# Reshape for LSTM (Samples, Time Steps, Features)\n",
        "class_train_X = class_train_X.reshape((class_train_X.shape[0], 1, class_train_X.shape[1]))\n",
        "class_test_X = class_test_X.reshape((class_test_X.shape[0], 1, class_test_X.shape[1]))\n",
        "\n",
        "# Apply SMOTE for Balancing\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(\n",
        "    class_train_X.reshape(class_train_X.shape[0], -1), class_train_Y\n",
        ")\n",
        "class_train_X_smote = class_train_X_smote.reshape((class_train_X_smote.shape[0], 1, class_train_X_smote.shape[1]))\n",
        "\n",
        "# ===================== LSTM MODEL ===================== #\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu'), input_shape=(1, class_train_X.shape[2])))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=False, activation='relu')))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(len(class_target), activation='softmax'))  # Multi-class output\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile and Train Model\n",
        "lstm_model = build_lstm_model()\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                   loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "lstm_model.fit(class_train_X_smote, class_train_Y_smote, epochs=100, batch_size=32, validation_data=(class_test_X, class_test_Y), verbose=1)\n",
        "\n",
        "# Predictions and Accuracy\n",
        "lstm_preds = np.argmax(lstm_model.predict(class_test_X), axis=1)\n",
        "lstm_accuracy = accuracy_score(class_test_Y, lstm_preds)\n",
        "print(f\"LSTM + DWT Classification Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "# ===================== CHECK ACCURACY ===================== #\n",
        "if lstm_accuracy >= 0.95:\n",
        "    print(\"Achieved 95%+ Accuracy! 🎉\")\n",
        "else:\n",
        "    print(\"⚠️ Still below 95%, consider deeper tuning.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F6ULLzTtzOTw"
      },
      "id": "F6ULLzTtzOTw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN**"
      ],
      "metadata": {
        "id": "olXCVRJ5Gml6"
      },
      "id": "olXCVRJ5Gml6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import xgboost as Xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ===================== Load Data ===================== #\n",
        "# Assuming class_train is your dataset\n",
        "print(\"Columns in dataset:\", class_train.columns)  # Debugging Step\n",
        "\n",
        "# Fix KeyError: Ensure column names are correct\n",
        "if 'Fault_Type' not in class_train.columns:\n",
        "    print(\"Error: Column 'Fault_Type' not found! Check column names.\")\n",
        "    exit()\n",
        "\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "target = 'Fault_Type'\n",
        "\n",
        "# Split Features & Labels\n",
        "X = class_train[features]\n",
        "y = class_train[target]\n",
        "\n",
        "# Encode Labels (Convert to Numeric)\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize Data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ===================== XGBoost for Detection ===================== #\n",
        "xgb = Xgb.XGBClassifier(n_estimators=50, learning_rate=0.05, max_depth=6, objective='multi:softmax', num_class=len(set(y)))\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "# ===================== CNN-LSTM Model for Classification ===================== #\n",
        "X_train_lstm = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_lstm = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_lstm.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(len(set(y)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test), verbose=1)\n",
        "\n",
        "# Evaluate Model\n",
        "lstm_preds = np.argmax(model.predict(X_test_lstm), axis=1)\n",
        "lstm_accuracy = accuracy_score(y_test, lstm_preds)\n",
        "print(f\" CNN-LSTM Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "# ===================== Confusion Matrix ===================== #\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, lstm_preds), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - CNN-LSTM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== Model Selection ===================== #\n",
        "best_model, best_accuracy = max([('XGBoost', xgb_accuracy), ('CNN-LSTM', lstm_accuracy)], key=lambda x: x[1])\n",
        "print(f\"Best Model: {best_model} with Accuracy: {best_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "EhnhcFYaK-DD"
      },
      "id": "EhnhcFYaK-DD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ===================== DATA PREPROCESSING ===================== #\n",
        "\n",
        "# Define input features and class labels\n",
        "features = ['Va', 'Vb', 'Vc', 'Ia', 'Ib', 'Ic']\n",
        "class_target = ['G', 'C', 'B', 'A']\n",
        "\n",
        "# Load your dataset (Assuming detection_train and class_train are already loaded)\n",
        "detection_data_X = detection_train[features]\n",
        "class_data_X = class_train[features]\n",
        "detection_data_Y = detection_train['Output(S)']\n",
        "class_data_Y = class_train[class_target]\n",
        "\n",
        "# Convert class labels to numerical format\n",
        "encoder = LabelEncoder()\n",
        "class_data_Y = encoder.fit_transform(np.argmax(class_data_Y.values, axis=1))\n",
        "\n",
        "# Split data into train and test sets\n",
        "class_train_X, class_test_X, class_train_Y, class_test_Y = train_test_split(\n",
        "    class_data_X, class_data_Y, test_size=0.2, random_state=1, stratify=class_data_Y)\n",
        "\n",
        "detection_train_X, detection_test_X, detection_train_Y, detection_test_Y = train_test_split(\n",
        "    detection_data_X, detection_data_Y, test_size=0.2, random_state=1, stratify=detection_data_Y)\n",
        "\n",
        "# Standardizing Data\n",
        "scaler = StandardScaler()\n",
        "class_train_X = scaler.fit_transform(class_train_X)\n",
        "class_test_X = scaler.transform(class_test_X)\n",
        "detection_train_X = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X = scaler.transform(detection_test_X)\n",
        "\n",
        "# ===================== DATA BALANCING WITH SMOTE ===================== #\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=1)\n",
        "class_train_X_smote, class_train_Y_smote = smote.fit_resample(class_train_X, class_train_Y)\n",
        "\n",
        "# ===================== BUILDING ANN MODEL ===================== #\n",
        "def build_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(class_train_X.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(class_target), activation='softmax')  # Multi-Class Output\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Instantiate and train the ANN model\n",
        "model_ann = build_ann_model()\n",
        "history = model_ann.fit(class_train_X_smote, class_train_Y_smote,\n",
        "                        epochs=100, batch_size=32,\n",
        "                        validation_data=(class_test_X, class_test_Y), verbose=1)\n",
        "\n",
        "# ===================== MODEL EVALUATION ===================== #\n",
        "# Make predictions\n",
        "ann_preds = np.argmax(model_ann.predict(class_test_X), axis=1)\n",
        "ann_accuracy = accuracy_score(class_test_Y, ann_preds)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\" ANN Classification Accuracy: {ann_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-dZq7-pZGmwj"
      },
      "id": "-dZq7-pZGmwj",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8554e190",
      "cell_type": "code",
      "source": [
        "#Defining different Models for different classification problems\n",
        "detection_model = linear_model.Lasso(alpha = 2.0)\n",
        "class_model = LinearRegression()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.010049,
          "end_time": "2025-02-02T19:35:51.986452",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.976403",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:33.718691Z",
          "iopub.execute_input": "2025-02-17T05:58:33.719033Z",
          "iopub.status.idle": "2025-02-17T05:58:33.723425Z",
          "shell.execute_reply.started": "2025-02-17T05:58:33.719003Z",
          "shell.execute_reply": "2025-02-17T05:58:33.722397Z"
        },
        "id": "8554e190"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "11816852",
      "cell_type": "code",
      "source": [
        "#Fitting the data in different models\n",
        "detection_model.fit(detection_train_X,detection_train_Y)\n",
        "class_Y = np.array([class_train_Y['G']*1+class_train_Y['A']*2+class_train_Y['B']*3+class_train_Y['C']*5])\n",
        "class_Y= class_Y.transpose().ravel()\n",
        "class_model.fit(class_train_X,class_Y)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.133261,
          "end_time": "2025-02-02T19:35:52.125968",
          "exception": false,
          "start_time": "2025-02-02T19:35:51.992707",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:36.802518Z",
          "iopub.execute_input": "2025-02-17T05:58:36.802930Z",
          "iopub.status.idle": "2025-02-17T05:58:36.893694Z",
          "shell.execute_reply.started": "2025-02-17T05:58:36.802896Z",
          "shell.execute_reply": "2025-02-17T05:58:36.892890Z"
        },
        "id": "11816852"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "59659090",
      "cell_type": "code",
      "source": [
        "#Predicting test values and printing out Mean Squared Error\n",
        "detection_preds = detection_model.predict(detection_test_X)\n",
        "print('The Error of our Detection Model is: ',mean_squared_error(detection_test_Y,detection_preds))\n",
        "\n",
        "class_Y = np.array([class_test_Y['G']*1+class_test_Y['A']*2+class_test_Y['B']*3+class_test_Y['C']*4])\n",
        "class_Y= class_Y.transpose().ravel()\n",
        "class_preds = class_model.predict(class_test_X)\n",
        "print('The Error of our Classification Model is: ',mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "#storing error values\n",
        "detect_error.append(mean_squared_error(detection_test_Y,detection_preds))\n",
        "class_error.append(mean_squared_error(class_Y,class_preds))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01967,
          "end_time": "2025-02-02T19:35:52.152042",
          "exception": false,
          "start_time": "2025-02-02T19:35:52.132372",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:40.117193Z",
          "iopub.execute_input": "2025-02-17T05:58:40.117496Z",
          "iopub.status.idle": "2025-02-17T05:58:40.129309Z",
          "shell.execute_reply.started": "2025-02-17T05:58:40.117473Z",
          "shell.execute_reply": "2025-02-17T05:58:40.128487Z"
        },
        "id": "59659090"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "83c94901",
      "cell_type": "code",
      "source": [
        "# Printing out accuracy scores of our models\n",
        "print('The accuracy score of our Detection Model is: ',(detection_model.score(detection_test_X,detection_test_Y)))\n",
        "print('The accuracy score of our Classification Model is: ',(class_model.score(class_test_X,class_Y)))\n",
        "\n",
        "#Storing accuracy values\n",
        "detect_accuracy.append((detection_model.score(detection_test_X,detection_test_Y)))\n",
        "class_accuracy.append((class_model.score(class_test_X,class_Y)))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018146,
          "end_time": "2025-02-02T19:35:52.177444",
          "exception": false,
          "start_time": "2025-02-02T19:35:52.159298",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:58:44.081765Z",
          "iopub.execute_input": "2025-02-17T05:58:44.082066Z",
          "iopub.status.idle": "2025-02-17T05:58:44.094546Z",
          "shell.execute_reply.started": "2025-02-17T05:58:44.082044Z",
          "shell.execute_reply": "2025-02-17T05:58:44.093766Z"
        },
        "id": "83c94901"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4140f828",
      "cell_type": "markdown",
      "source": [
        "**Multi layer Perceptron**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005837,
          "end_time": "2025-02-02T19:35:52.189390",
          "exception": false,
          "start_time": "2025-02-02T19:35:52.183553",
          "status": "completed"
        },
        "tags": [],
        "id": "4140f828"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining different Models for different classification problems\n",
        "\n",
        "detection_model = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(5, 2), random_state=1,max_iter = 1000)\n",
        "class_model = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    hidden_layer_sizes=(10, 6), random_state=1,max_iter = 5000)\n",
        "\n",
        "#Fitting the data in different models\n",
        "\n",
        "detection_model.fit(detection_train_X,detection_train_Y)\n",
        "class_model.fit(class_train_X,class_train_Y)\n",
        "\n",
        "#Predicting test values and printing out Mean Squared Error\n",
        "\n",
        "detection_preds = detection_model.predict(detection_test_X)\n",
        "print('The Error of our Detection Model is: ',mean_squared_error(detection_test_Y,detection_preds))\n",
        "\n",
        "class_preds = class_model.predict(class_test_X)\n",
        "print('The Error of our Classification Model is: ',mean_squared_error(class_test_Y,class_preds))\n",
        "\n",
        "#storing error values\n",
        "\n",
        "detect_error.append(mean_squared_error(detection_test_Y,detection_preds))\n",
        "class_error.append(mean_squared_error(class_test_Y,class_preds))\n",
        "\n",
        "# Printing out accuracy scores of our models\n",
        "\n",
        "print('\\nThe accuracy score of our Detection Model is: ',(detection_model.score(detection_test_X,detection_test_Y)))\n",
        "print('The accuracy score of our Classification Model is: ',(class_model.score(class_test_X,class_test_Y)))\n",
        "\n",
        "#Storing accuracy values\n",
        "detect_accuracy.append((detection_model.score(detection_test_X,detection_test_Y)))\n",
        "class_accuracy.append((class_model.score(class_test_X,class_test_Y)))"
      ],
      "metadata": {
        "id": "tlx89nqDNwFf"
      },
      "id": "tlx89nqDNwFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c937fe1e-d0a9-4854-9e21-4296e88a16db",
      "cell_type": "markdown",
      "source": [
        "****Multi layer Perceptron - Hyperparameter Tuning****"
      ],
      "metadata": {
        "id": "c937fe1e-d0a9-4854-9e21-4296e88a16db"
      }
    },
    {
      "id": "208772db-583d-4f31-a405-78caffbb10a1",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "\n",
        "# 🟢 Step 1: Define Hyperparameter Grid\n",
        "mlp_param_grid = {\n",
        "    'hidden_layer_sizes': [(5, 2), (10, 5), (50, 25), (100, 50)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam', 'lbfgs'],\n",
        "    'alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# 🟢 Step 2: Hyperparameter Tuning for Detection Model\n",
        "random_search_detection = RandomizedSearchCV(MLPClassifier(max_iter=5000, random_state=42),\n",
        "                                             param_distributions=mlp_param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_mlp_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# 🟢 Step 3: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(MLPClassifier(max_iter=5000, random_state=42),\n",
        "                                                  param_distributions=mlp_param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_train_Y)\n",
        "best_mlp_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# 🟢 Step 4: Model Predictions\n",
        "detection_preds = best_mlp_detection_model.predict(detection_test_X)\n",
        "class_preds = best_mlp_class_model.predict(class_test_X)\n",
        "\n",
        "# 🟢 Step 5: Mean Squared Error\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "classification_mse = mean_squared_error(class_test_Y, class_preds)\n",
        "\n",
        "# 🟢 Step 6: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "\n",
        "# 🟢 Step 7: Print Accuracy & MSE Results\n",
        "print(\"\\n Optimized MLP Classifier Model Performance \")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Detection Model Mean Squared Error: {detection_mse:.4f}\")\n",
        "print(f\"Classification Model Mean Squared Error: {classification_mse:.4f}\")\n",
        "print(f\"MLP Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"MLP Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# 🟢 Step 8: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_test_Y, class_preds))\n",
        "\n",
        "# 🟢 Step 9: Storing Accuracy & Error Values\n",
        "detect_error.append(detection_mse)\n",
        "class_error.append(classification_mse)\n",
        "detect_accuracy.append(detection_accuracy)\n",
        "class_accuracy.append(classification_accuracy)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T17:37:41.049902Z",
          "iopub.execute_input": "2025-02-15T17:37:41.050241Z",
          "iopub.status.idle": "2025-02-15T17:49:57.568178Z",
          "shell.execute_reply.started": "2025-02-15T17:37:41.050219Z",
          "shell.execute_reply": "2025-02-15T17:49:57.567199Z"
        },
        "id": "208772db-583d-4f31-a405-78caffbb10a1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "10f68baa",
      "cell_type": "markdown",
      "source": [
        "**KNN (K-Nearest Neighbors)**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006683,
          "end_time": "2025-02-02T19:36:02.557941",
          "exception": false,
          "start_time": "2025-02-02T19:36:02.551258",
          "status": "completed"
        },
        "tags": [],
        "id": "10f68baa"
      }
    },
    {
      "id": "4909605a",
      "cell_type": "code",
      "source": [
        "#Defining different Models for different classification problems\n",
        "detection_model = KNeighborsClassifier(n_neighbors=2)\n",
        "class_model = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "#Fitting the data in different models\n",
        "detection_model.fit(detection_train_X,detection_train_Y)\n",
        "class_Y = np.array([class_train_Y['G']*1+class_train_Y['A']\n",
        "                    *2+class_train_Y['B']*3+class_train_Y['C']*5])\n",
        "class_Y= class_Y.transpose().ravel()\n",
        "class_model.fit(class_train_X,class_Y)\n",
        "\n",
        "#Predicting test values and printing out Mean Squared Error\n",
        "detection_preds = detection_model.predict(detection_test_X)\n",
        "print('The Error of our Detection Model is: ',mean_squared_error(detection_test_Y,detection_preds))\n",
        "\n",
        "class_Y = np.array([class_test_Y['G']*1+class_test_Y['A']*2+class_test_Y['B']*3+class_test_Y['C']*5])\n",
        "class_Y = class_Y.transpose().ravel()\n",
        "class_preds = class_model.predict(class_test_X)\n",
        "print('The Error of our Classification Model is: ',mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "#storing error values\n",
        "detect_error.append(mean_squared_error(detection_test_Y,detection_preds))\n",
        "class_error.append(mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "# Printing out accuracy scores of our models\n",
        "print('\\nThe accuracy score of our Detection Model is: ',(detection_model.score(detection_test_X,detection_test_Y)))\n",
        "print('The accuracy score of our Classification Model is: ',(class_model.score(class_test_X,class_Y)))\n",
        "\n",
        "#Storing accuracy values\n",
        "detect_accuracy.append((detection_model.score(detection_test_X,detection_test_Y)))\n",
        "class_accuracy.append((class_model.score(class_test_X,class_Y)))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006969,
          "end_time": "2025-02-02T19:36:03.513250",
          "exception": false,
          "start_time": "2025-02-02T19:36:03.506281",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T17:53:10.175321Z",
          "iopub.execute_input": "2025-02-15T17:53:10.175633Z",
          "iopub.status.idle": "2025-02-15T17:53:10.974072Z",
          "shell.execute_reply.started": "2025-02-15T17:53:10.175610Z",
          "shell.execute_reply": "2025-02-15T17:53:10.973418Z"
        },
        "id": "4909605a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d609c685-05f0-4077-ace0-50de65ae8303",
      "cell_type": "markdown",
      "source": [
        "**KNN - Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "d609c685-05f0-4077-ace0-50de65ae8303"
      }
    },
    {
      "id": "882da9fc-8a7d-48fb-8352-69c0746b4806",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# ===================== DETECTION MODEL (KNN) ===================== #\n",
        "\n",
        "# Define Pipeline (Feature Scaling + KNN)\n",
        "knn_detection_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Define Hyperparameter Grid for Detection Model\n",
        "knn_detection_param_grid = {\n",
        "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Perform Grid Search for Best Hyperparameters\n",
        "grid_search_detection = GridSearchCV(knn_detection_pipeline, param_grid=knn_detection_param_grid,\n",
        "                                     cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Best Detection Model\n",
        "best_knn_detection_model = grid_search_detection.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "detection_preds = best_knn_detection_model.predict(detection_test_X)\n",
        "\n",
        "# Mean Squared Error\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "\n",
        "# Accuracy\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "\n",
        "# Print Detection Model Metrics\n",
        "print(\"\\n🔹 Optimized KNN Detection Model Performance\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Detection Model Mean Squared Error: {detection_mse:.4f}\")\n",
        "print(f\"Optimized KNN Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "# Store Detection Accuracy & Error\n",
        "detect_error.append(detection_mse)\n",
        "detect_accuracy.append(detection_accuracy)\n",
        "\n",
        "# ===================== DETECTION MODEL KNN CONFUSION MATRIX ===================== #\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(detection_test_Y, detection_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Fault (0)\", \"Fault (1)\"], yticklabels=[\"No Fault (0)\", \"Fault (1)\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Detection Model KNN Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== CLASSIFICATION MODEL (KNN) ===================== #\n",
        "\n",
        "# Define Pipeline (Feature Scaling + KNN)\n",
        "knn_class_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Define Hyperparameter Grid for Classification Model\n",
        "knn_class_param_grid = {\n",
        "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Perform Grid Search for Best Hyperparameters\n",
        "grid_search_class = GridSearchCV(knn_class_pipeline, param_grid=knn_class_param_grid,\n",
        "                                 cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search_class.fit(class_train_X, class_train_Y)\n",
        "\n",
        "# Best Classification Model\n",
        "best_knn_class_model = grid_search_class.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "class_preds = best_knn_class_model.predict(class_test_X)\n",
        "\n",
        "# Mean Squared Error\n",
        "classification_mse = mean_squared_error(class_test_Y, class_preds)\n",
        "\n",
        "# Accuracy\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "\n",
        "# Print Classification Model Metrics\n",
        "print(\"\\n🔹 Optimized KNN Classification Model Performance\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Classification Model Mean Squared Error: {classification_mse:.4f}\")\n",
        "print(f\"Optimized KNN Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(class_test_Y, class_preds))\n",
        "\n",
        "# Store Classification Accuracy & Error\n",
        "class_error.append(classification_mse)\n",
        "class_accuracy.append(classification_accuracy)\n",
        "\n",
        "# ===================== CLASSIFICATION MODEL KNN CONFUSION MATRIX ===================== #\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(class_test_Y, class_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix ---- KNN Classification Model\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T17:59:49.559767Z",
          "iopub.execute_input": "2025-02-15T17:59:49.560159Z",
          "iopub.status.idle": "2025-02-15T18:00:00.665572Z",
          "shell.execute_reply.started": "2025-02-15T17:59:49.560130Z",
          "shell.execute_reply": "2025-02-15T18:00:00.664708Z"
        },
        "id": "882da9fc-8a7d-48fb-8352-69c0746b4806"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8559791c",
      "cell_type": "markdown",
      "source": [
        "**Decision tree classifier**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.007408,
          "end_time": "2025-02-02T19:36:04.042650",
          "exception": false,
          "start_time": "2025-02-02T19:36:04.035242",
          "status": "completed"
        },
        "tags": [],
        "id": "8559791c"
      }
    },
    {
      "id": "75ab990f",
      "cell_type": "code",
      "source": [
        "#Defining different Models for different classification problems\n",
        "detection_model = DecisionTreeClassifier()\n",
        "class_model = DecisionTreeClassifier()\n",
        "\n",
        "#Fitting the data in different models\n",
        "detection_model.fit(detection_train_X,detection_train_Y)\n",
        "class_Y = np.array([class_train_Y['G']*1+class_train_Y['A']\n",
        "                    *2+class_train_Y['B']*3+class_train_Y['C']*5])\n",
        "class_Y= class_Y.transpose().ravel()\n",
        "class_model.fit(class_train_X,class_Y)\n",
        "\n",
        "#Predicting test values and printing out Mean Squared Error\n",
        "detection_preds = detection_model.predict(detection_test_X)\n",
        "print('The Error of our Detection Model is: ',mean_squared_error(detection_test_Y,detection_preds))\n",
        "\n",
        "class_Y = np.array([class_test_Y['G']*1+class_test_Y['A']*2+class_test_Y['B']*3+class_test_Y['C']*5])\n",
        "class_Y = class_Y.transpose().ravel()\n",
        "class_preds = class_model.predict(class_test_X)\n",
        "print('The Error of our Classification Model is: ',mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "#storing error values\n",
        "detect_error.append(mean_squared_error(detection_test_Y,detection_preds))\n",
        "class_error.append(mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "# Printing out accuracy scores of our models\n",
        "print('\\nThe accuracy score of our Detection Model is: ',(detection_model.score(detection_test_X,detection_test_Y)))\n",
        "print('The accuracy score of our Classification Model is: ',(class_model.score(class_test_X,class_Y)))\n",
        "\n",
        "#Storing accuracy values\n",
        "detect_accuracy.append((detection_model.score(detection_test_X,detection_test_Y)))\n",
        "class_accuracy.append((class_model.score(class_test_X,class_Y)))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012334,
          "end_time": "2025-02-02T19:36:04.062670",
          "exception": false,
          "start_time": "2025-02-02T19:36:04.050336",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T18:01:11.559286Z",
          "iopub.execute_input": "2025-02-15T18:01:11.559606Z",
          "iopub.status.idle": "2025-02-15T18:01:11.667082Z",
          "shell.execute_reply.started": "2025-02-15T18:01:11.559579Z",
          "shell.execute_reply": "2025-02-15T18:01:11.666378Z"
        },
        "id": "75ab990f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ad50d59a-9213-4d9b-aa3c-112f2bb9a9b7",
      "cell_type": "markdown",
      "source": [
        "**Decision tree classifier- hyper parameter tuning**"
      ],
      "metadata": {
        "id": "ad50d59a-9213-4d9b-aa3c-112f2bb9a9b7"
      }
    },
    {
      "id": "8f37f19a-4199-4ac2-82c0-81a51daef041",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "\n",
        "#  Step 1: Define Hyperparameter Grid\n",
        "dt_param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': list(range(3, 30)),\n",
        "    'min_samples_split': list(range(2, 10)),\n",
        "    'min_samples_leaf': list(range(1, 10))\n",
        "}\n",
        "\n",
        "#  Step 2: Hyperparameter Tuning for Detection Model\n",
        "random_search_detection = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                                             param_distributions=dt_param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_dt_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "#  Step 3: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                                                  param_distributions=dt_param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_train_Y)\n",
        "best_dt_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# Step 4: Model Predictions\n",
        "detection_preds = best_dt_detection_model.predict(detection_test_X)\n",
        "class_preds = best_dt_class_model.predict(class_test_X)\n",
        "\n",
        "#  Step 5: Mean Squared Error\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "classification_mse = mean_squared_error(class_test_Y, class_preds)\n",
        "\n",
        "#  Step 6: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "\n",
        "#  Step 7: Print Accuracy & MSE Results\n",
        "print(\"\\n🟢 Optimized Decision Tree Classifier Model Performance 🟢\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Detection Model Mean Squared Error: {detection_mse:.4f}\")\n",
        "print(f\"Classification Model Mean Squared Error: {classification_mse:.4f}\")\n",
        "print(f\"Decision Tree Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"Decision Tree Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "#  Step 8: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_test_Y, class_preds))\n",
        "\n",
        "#  Step 9: Storing Accuracy & Error Values\n",
        "detect_error.append(detection_mse)\n",
        "class_error.append(classification_mse)\n",
        "detect_accuracy.append(detection_accuracy)\n",
        "class_accuracy.append(classification_accuracy)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T18:01:22.309713Z",
          "iopub.execute_input": "2025-02-15T18:01:22.310032Z",
          "iopub.status.idle": "2025-02-15T18:01:23.133859Z",
          "shell.execute_reply.started": "2025-02-15T18:01:22.310006Z",
          "shell.execute_reply": "2025-02-15T18:01:23.133023Z"
        },
        "id": "8f37f19a-4199-4ac2-82c0-81a51daef041"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "16fe5fa3",
      "cell_type": "markdown",
      "source": [
        "**SVM (Support Vector Machine)**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.009826,
          "end_time": "2025-02-02T19:36:04.760193",
          "exception": false,
          "start_time": "2025-02-02T19:36:04.750367",
          "status": "completed"
        },
        "tags": [],
        "id": "16fe5fa3"
      }
    },
    {
      "id": "ba3973fb-680f-4d4a-a562-b5e0df37c7ea",
      "cell_type": "code",
      "source": [
        "#Defining different Models for different classification problems\n",
        "\n",
        "detection_model = SVC()\n",
        "class_model = LinearSVC()\n",
        "\n",
        "#Fitting the data in different models\n",
        "\n",
        "detection_model.fit(detection_train_X,detection_train_Y)\n",
        "class_Y = np.array([class_train_Y['G']*1+class_train_Y['A']\n",
        "                    *2+class_train_Y['B']*3+class_train_Y['C']*5])\n",
        "class_Y= class_Y.transpose().ravel()\n",
        "class_model.fit(class_train_X,class_Y)\n",
        "\n",
        "#Predicting test values and printing out Mean Squared Error\n",
        "\n",
        "detection_preds = detection_model.predict(detection_test_X)\n",
        "print('The Error of our Detection Model is: ',mean_squared_error(detection_test_Y,detection_preds))\n",
        "\n",
        "class_Y = np.array([class_test_Y['G']*1+class_test_Y['A']*2+class_test_Y['B']*3+class_test_Y['C']*5])\n",
        "class_Y = class_Y.transpose().ravel()\n",
        "class_preds = class_model.predict(class_test_X)\n",
        "print('The Error of our Classification Model is: ',mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "#storing error values\n",
        "\n",
        "detect_error.append(mean_squared_error(detection_test_Y,detection_preds))\n",
        "class_error.append(mean_squared_error(class_Y,class_preds))\n",
        "\n",
        "# Printing out accuracy scores of our models\n",
        "print('\\nThe accuracy score of our Detection Model is: ',(detection_model.score(detection_test_X,detection_test_Y)))\n",
        "print('The accuracy score of our Classification Model is: ',(class_model.score(class_test_X,class_Y)))\n",
        "\n",
        "#Storing accuracy values\n",
        "detect_accuracy.append((detection_model.score(detection_test_X,detection_test_Y)))\n",
        "class_accuracy.append((class_model.score(class_test_X,class_Y)))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:59:08.755889Z",
          "iopub.execute_input": "2025-02-17T05:59:08.756295Z",
          "iopub.status.idle": "2025-02-17T05:59:10.864432Z",
          "shell.execute_reply.started": "2025-02-17T05:59:08.756265Z",
          "shell.execute_reply": "2025-02-17T05:59:10.863802Z"
        },
        "id": "ba3973fb-680f-4d4a-a562-b5e0df37c7ea"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "367a6627-c536-4781-9782-d80034707d3c",
      "cell_type": "markdown",
      "source": [
        "**Support vector machine- Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "367a6627-c536-4781-9782-d80034707d3c"
      }
    },
    {
      "id": "d4a6d7c4-39fb-4bb3-b56b-cc5d196fcef9",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
        "\n",
        "#  Step 1: Define Hyperparameter Grids\n",
        "svc_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "linear_svc_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "#  Step 2: Hyperparameter Tuning for Detection Model (SVC)\n",
        "random_search_detection = RandomizedSearchCV(SVC(), param_distributions=svc_param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_svc_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "#  Step 3: Encode Multi-Class Labels for Classification\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).ravel()\n",
        "\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).ravel()\n",
        "\n",
        "#  Step 4: Hyperparameter Tuning for Classification Model (LinearSVC)\n",
        "random_search_classification = RandomizedSearchCV(LinearSVC(max_iter=5000), param_distributions=linear_svc_param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_Y_train)\n",
        "best_svc_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "#  Step 5: Model Predictions\n",
        "detection_preds = best_svc_detection_model.predict(detection_test_X)\n",
        "class_preds = best_svc_class_model.predict(class_test_X)\n",
        "\n",
        "#  Step 6: Mean Squared Error\n",
        "detection_mse = mean_squared_error(detection_test_Y, detection_preds)\n",
        "classification_mse = mean_squared_error(class_Y_test, class_preds)\n",
        "\n",
        "#  Step 7: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_Y_test, class_preds)\n",
        "\n",
        "#  Step 8: Print Accuracy & MSE Results\n",
        "print(\"\\n🟢 Optimized SVM Model Performance 🟢\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Detection Model Mean Squared Error: {detection_mse:.4f}\")\n",
        "print(f\"Classification Model Mean Squared Error: {classification_mse:.4f}\")\n",
        "print(f\"SVM Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"SVM Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "#  Step 9: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_Y_test, class_preds))\n",
        "\n",
        "#  Step 10: Storing Accuracy & Error Values\n",
        "detect_error.append(detection_mse)\n",
        "class_error.append(classification_mse)\n",
        "detect_accuracy.append(detection_accuracy)\n",
        "class_accuracy.append(classification_accuracy)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T05:59:22.156603Z",
          "iopub.execute_input": "2025-02-17T05:59:22.156945Z"
        },
        "id": "d4a6d7c4-39fb-4bb3-b56b-cc5d196fcef9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "410f3727",
      "cell_type": "markdown",
      "source": [
        "**Updated Code with Ensemble Learning**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.009744,
          "end_time": "2025-02-02T19:36:07.485078",
          "exception": false,
          "start_time": "2025-02-02T19:36:07.475334",
          "status": "completed"
        },
        "tags": [],
        "id": "410f3727"
      }
    },
    {
      "id": "092b94c2-6760-4ce1-a46d-6d60663321c0",
      "cell_type": "markdown",
      "source": [
        "**Bagging**"
      ],
      "metadata": {
        "id": "092b94c2-6760-4ce1-a46d-6d60663321c0"
      }
    },
    {
      "id": "c827a22d",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import BaggingClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "# Defining Bagging KNN Models\n",
        "bagging_detection_model = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=2),\n",
        "                                            n_estimators=10, random_state=42)\n",
        "bagging_class_model = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=6),\n",
        "                                        n_estimators=10, random_state=42)\n",
        "\n",
        "# Fit detection model\n",
        "bagging_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "bagging_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Now, create test labels correctly\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Ensure shape consistency before evaluation\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)  # Should match class_test_X.shape[0]\n",
        "\n",
        "# Now, compute accuracy with correct test labels\n",
        "print('Bagging Classification Model Accuracy:', bagging_class_model.score(class_test_X, class_Y_test))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Shape:\", class_Y.shape)\n",
        "\n",
        "# Predictions\n",
        "detection_preds = bagging_detection_model.predict(detection_test_X)\n",
        "class_preds = bagging_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy\n",
        "print('Bagging Detection Model Accuracy:', bagging_detection_model.score(detection_test_X, detection_test_Y))\n",
        "print('Bagging Classification Model Accuracy:', bagging_class_model.score(class_test_X, class_Y))\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014558,
          "end_time": "2025-02-02T19:36:07.682050",
          "exception": false,
          "start_time": "2025-02-02T19:36:07.667492",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-15T18:21:12.927606Z",
          "iopub.execute_input": "2025-02-15T18:21:12.927958Z",
          "iopub.status.idle": "2025-02-15T18:21:13.681052Z",
          "shell.execute_reply.started": "2025-02-15T18:21:12.927929Z",
          "shell.execute_reply": "2025-02-15T18:21:13.680107Z"
        },
        "id": "c827a22d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8fd57c05-ecf6-4602-ba9e-f9a840c230f6",
      "cell_type": "markdown",
      "source": [
        "**Bagging - Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "8fd57c05-ecf6-4602-ba9e-f9a840c230f6"
      }
    },
    {
      "id": "5c580a5e-4442-485e-b34c-327d69c04355",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "5c580a5e-4442-485e-b34c-327d69c04355"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c561a299-ff81-421c-ae08-db2bdc1cd195",
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting**"
      ],
      "metadata": {
        "id": "c561a299-ff81-421c-ae08-db2bdc1cd195"
      }
    },
    {
      "id": "cab9cbaa-d12b-438b-9d27-c5a0d9ced2e9",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining Gradient Boosting Models\n",
        "gb_detection_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_class_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Fit detection model\n",
        "gb_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "gb_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Now, create test labels correctly\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Ensure shape consistency before evaluation\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)  # Should match class_test_X.shape[0]\n",
        "\n",
        "# Compute accuracy with correct test labels\n",
        "print('Gradient Boosting Classification Model Accuracy:', gb_class_model.score(class_test_X, class_Y_test))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "\n",
        "# Predictions\n",
        "detection_preds = gb_detection_model.predict(detection_test_X)\n",
        "class_preds = gb_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy\n",
        "print('Gradient Boosting Detection Model Accuracy:', gb_detection_model.score(detection_test_X, detection_test_Y))\n",
        "print('Gradient Boosting Classification Model Accuracy:', gb_class_model.score(class_test_X, class_Y_test))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:03:54.878445Z",
          "iopub.execute_input": "2025-02-14T15:03:54.878728Z",
          "iopub.status.idle": "2025-02-14T15:04:03.958442Z",
          "shell.execute_reply.started": "2025-02-14T15:03:54.878708Z",
          "shell.execute_reply": "2025-02-14T15:04:03.957719Z"
        },
        "id": "cab9cbaa-d12b-438b-9d27-c5a0d9ced2e9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "25772bcc-4b30-4c14-b34b-af77e622a9d2",
      "cell_type": "markdown",
      "source": [
        "**Gradient - hyperParameter Tuning**"
      ],
      "metadata": {
        "id": "25772bcc-4b30-4c14-b34b-af77e622a9d2"
      }
    },
    {
      "id": "929ca41a-fa7d-45a6-a7da-8847bd1a2f90",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 🟢 Step 1: Define Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# 🟢 Step 2: Define Gradient Boosting Classifier\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# 🟢 Step 3: Hyperparameter Tuning for Detection Model\n",
        "random_search_detection = RandomizedSearchCV(gb_model, param_distributions=param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_gb_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# 🟢 Step 4: Encode Multi-Class Labels Correctly (for Classification)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).ravel()\n",
        "\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).ravel()\n",
        "\n",
        "# 🟢 Step 5: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(gb_model, param_distributions=param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_Y_train)\n",
        "best_gb_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# 🟢 Step 6: Model Predictions\n",
        "detection_preds = best_gb_detection_model.predict(detection_test_X)\n",
        "class_preds = best_gb_class_model.predict(class_test_X)\n",
        "\n",
        "# 🟢 Step 7: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_Y_test, class_preds)\n",
        "\n",
        "# 🟢 Step 8: Print Results\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)\n",
        "print(\"Gradient Boosting Classification Model Accuracy:\", classification_accuracy)\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "print(\"Gradient Boosting Detection Model Accuracy:\", detection_accuracy)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:04:03.959318Z",
          "iopub.execute_input": "2025-02-14T15:04:03.959654Z",
          "iopub.status.idle": "2025-02-14T15:11:18.855919Z",
          "shell.execute_reply.started": "2025-02-14T15:04:03.959624Z",
          "shell.execute_reply": "2025-02-14T15:11:18.854905Z"
        },
        "id": "929ca41a-fa7d-45a6-a7da-8847bd1a2f90"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4713eba5-cdbb-4875-848a-743254b3ecb9",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 🟢 Step 1: Define Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# 🟢 Step 2: Define Gradient Boosting Classifier\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# 🟢 Step 3: Hyperparameter Tuning for Detection Model\n",
        "random_search_detection = RandomizedSearchCV(gb_model, param_distributions=param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_gb_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# 🟢 Step 4: Encode Multi-Class Labels Correctly (for Classification)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).ravel()\n",
        "\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).ravel()\n",
        "\n",
        "# 🟢 Step 5: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(gb_model, param_distributions=param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_Y_train)\n",
        "best_gb_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# 🟢 Step 6: Model Predictions\n",
        "detection_preds = best_gb_detection_model.predict(detection_test_X)\n",
        "class_preds = best_gb_class_model.predict(class_test_X)\n",
        "\n",
        "# 🟢 Step 7: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_Y_test, class_preds)\n",
        "\n",
        "# 🟢 Step 8: Print Accuracy Results\n",
        "print(\"\\n🟢 Gradient Boosting Model Performance 🟢\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Gradient Boosting Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"Gradient Boosting Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# 🟢 Step 9: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_Y_test, class_preds))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:11:18.857270Z",
          "iopub.execute_input": "2025-02-14T15:11:18.857640Z",
          "iopub.status.idle": "2025-02-14T15:18:25.346625Z",
          "shell.execute_reply.started": "2025-02-14T15:11:18.857600Z",
          "shell.execute_reply": "2025-02-14T15:18:25.345720Z"
        },
        "id": "4713eba5-cdbb-4875-848a-743254b3ecb9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6fec96fb-01ab-4acf-86fe-bc4b042fc22a",
      "cell_type": "markdown",
      "source": [
        "**random forest**"
      ],
      "metadata": {
        "id": "6fec96fb-01ab-4acf-86fe-bc4b042fc22a"
      }
    },
    {
      "id": "6e44128a-e1a9-4634-981f-cece311acad0",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining Random Forest Models\n",
        "rf_detection_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "rf_class_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# Fit detection model\n",
        "rf_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "rf_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Now, create test labels correctly\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Ensure shape consistency before evaluation\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)  # Should match class_test_X.shape[0]\n",
        "\n",
        "# Compute accuracy with correct test labels\n",
        "print('Random Forest Classification Model Accuracy:', rf_class_model.score(class_test_X, class_Y_test))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "\n",
        "# Predictions\n",
        "detection_preds = rf_detection_model.predict(detection_test_X)\n",
        "class_preds = rf_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy\n",
        "print('Random Forest Detection Model Accuracy:', rf_detection_model.score(detection_test_X, detection_test_Y))\n",
        "print('Random Forest Classification Model Accuracy:', rf_class_model.score(class_test_X, class_Y_test))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T16:52:02.229196Z",
          "iopub.execute_input": "2025-02-14T16:52:02.229573Z",
          "iopub.status.idle": "2025-02-14T16:52:03.902100Z",
          "shell.execute_reply.started": "2025-02-14T16:52:02.229544Z",
          "shell.execute_reply": "2025-02-14T16:52:03.901319Z"
        },
        "id": "6e44128a-e1a9-4634-981f-cece311acad0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e1be1e8a-9f7a-495f-8906-29de105209a8",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 🟢 Step 1: Define Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# 🟢 Step 2: Define Random Forest Model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 🟢 Step 3: Hyperparameter Tuning for Detection Model\n",
        "random_search_detection = RandomizedSearchCV(rf_model, param_distributions=param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_rf_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# 🟢 Step 4: Encode Multi-Class Labels Correctly (for Classification)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).ravel()\n",
        "\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).ravel()\n",
        "\n",
        "# 🟢 Step 5: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(rf_model, param_distributions=param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_Y_train)\n",
        "best_rf_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# 🟢 Step 6: Model Predictions\n",
        "detection_preds = best_rf_detection_model.predict(detection_test_X)\n",
        "class_preds = best_rf_class_model.predict(class_test_X)\n",
        "\n",
        "# 🟢 Step 7: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_Y_test, class_preds)\n",
        "\n",
        "# 🟢 Step 8: Print Accuracy Results\n",
        "print(\"\\n🟢 Random Forest Model Performance 🟢\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Random Forest Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"Random Forest Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# 🟢 Step 9: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_Y_test, class_preds))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T16:52:42.132930Z",
          "iopub.execute_input": "2025-02-14T16:52:42.133269Z",
          "iopub.status.idle": "2025-02-14T16:53:20.883339Z",
          "shell.execute_reply.started": "2025-02-14T16:52:42.133240Z",
          "shell.execute_reply": "2025-02-14T16:53:20.882291Z"
        },
        "id": "e1be1e8a-9f7a-495f-8906-29de105209a8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b6fb4810-9577-4ed8-995a-4e8bd92b71cf",
      "cell_type": "markdown",
      "source": [
        "**Voting Ensemble Implementation**"
      ],
      "metadata": {
        "id": "b6fb4810-9577-4ed8-995a-4e8bd92b71cf"
      }
    },
    {
      "id": "9923ea8e-ad2b-40ab-8662-ab7f93ace9c7",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Feature scaling (Important for KNN & Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Optimized base models\n",
        "rf_model = RandomForestClassifier(n_estimators=400, max_depth=20, min_samples_split=3,\n",
        "                                  min_samples_leaf=2, class_weight='balanced', random_state=42)\n",
        "\n",
        "knn_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Apply feature scaling for KNN\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=3, weights='distance', metric='euclidean'))\n",
        "])\n",
        "\n",
        "lr_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Scale features for Logistic Regression\n",
        "    ('lr', LogisticRegression(C=1.2, max_iter=1000, solver='lbfgs', penalty='l2', random_state=42))\n",
        "])\n",
        "\n",
        "# Define Voting Classifier with Soft Voting and better weights\n",
        "voting_detection_model = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model), ('knn', knn_model), ('lr', lr_model)],\n",
        "    voting='soft', weights=[5, 3, 1])  # Higher weight for RF\n",
        "\n",
        "voting_class_model = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model), ('knn', knn_model), ('lr', lr_model)],\n",
        "    voting='soft', weights=[5, 3, 1])  # Higher weight for RF\n",
        "\n",
        "# Fit detection model\n",
        "voting_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "voting_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Test labels\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Predictions\n",
        "detection_preds = voting_detection_model.predict(detection_test_X)\n",
        "class_preds = voting_class_model.predict(class_test_X)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "detection_accuracy = voting_detection_model.score(detection_test_X, detection_test_Y)\n",
        "classification_accuracy = voting_class_model.score(class_test_X, class_Y_test)\n",
        "\n",
        "print('Optimized Voting Detection Model Accuracy:', detection_accuracy)\n",
        "print('Optimized Voting Classification Model Accuracy:', classification_accuracy)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T16:55:26.191897Z",
          "iopub.execute_input": "2025-02-14T16:55:26.192261Z",
          "iopub.status.idle": "2025-02-14T16:55:34.882144Z",
          "shell.execute_reply.started": "2025-02-14T16:55:26.192232Z",
          "shell.execute_reply": "2025-02-14T16:55:34.881264Z"
        },
        "id": "9923ea8e-ad2b-40ab-8662-ab7f93ace9c7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "987bf04e-726e-4342-93d5-26281f25e326",
      "cell_type": "markdown",
      "source": [
        "**Voting - Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "987bf04e-726e-4342-93d5-26281f25e326"
      }
    },
    {
      "id": "b7c55c2f-e0d0-4e5f-8acd-a7e034b74c8f",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 🟢 Step 1: Define Hyperparameter Grids for Each Model\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 400],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 3, 5],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "knn_param_grid = {\n",
        "    'knn__n_neighbors': [3, 5, 7],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "lr_param_grid = {\n",
        "    'lr__C': [0.5, 1, 1.5],\n",
        "    'lr__solver': ['lbfgs', 'saga'],\n",
        "    'lr__penalty': ['l2']\n",
        "}\n",
        "\n",
        "# 🟢 Step 2: Define Optimized Base Models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "knn_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "lr_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# 🟢 Step 3: Define Voting Classifier (with Default Models)\n",
        "voting_model = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model), ('knn', knn_model), ('lr', lr_model)],\n",
        "    voting='soft')\n",
        "\n",
        "# 🟢 Step 4: Hyperparameter Tuning for Detection Model\n",
        "param_grid = {**{f'rf__{key}': value for key, value in rf_param_grid.items()},\n",
        "              **{f'knn__{key}': value for key, value in knn_param_grid.items()},\n",
        "              **{f'lr__{key}': value for key, value in lr_param_grid.items()}}\n",
        "\n",
        "random_search_detection = RandomizedSearchCV(voting_model, param_distributions=param_grid,\n",
        "                                             n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)\n",
        "best_voting_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# 🟢 Step 5: Encode Multi-Class Labels for Classification\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).ravel()\n",
        "\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).ravel()\n",
        "\n",
        "# 🟢 Step 6: Hyperparameter Tuning for Classification Model\n",
        "random_search_classification = RandomizedSearchCV(voting_model, param_distributions=param_grid,\n",
        "                                                  n_iter=10, cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_Y_train)\n",
        "best_voting_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# 🟢 Step 7: Model Predictions\n",
        "detection_preds = best_voting_detection_model.predict(detection_test_X)\n",
        "class_preds = best_voting_class_model.predict(class_test_X)\n",
        "\n",
        "# 🟢 Step 8: Accuracy Scores\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_Y_test, class_preds)\n",
        "\n",
        "# 🟢 Step 9: Print Accuracy Results\n",
        "print(\"\\n🟢 Optimized Voting Model Performance 🟢\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Voting Detection Model Accuracy: {detection_accuracy:.4f}\")\n",
        "print(f\"Voting Classification Model Accuracy: {classification_accuracy:.4f}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "# 🟢 Step 10: Precision, Recall, F1-Score, and Support Count\n",
        "print(\"\\n📊 Classification Report for Detection Model 📊\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n📊 Classification Report for Classification Model 📊\")\n",
        "print(classification_report(class_Y_test, class_preds))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T16:56:06.200098Z",
          "iopub.execute_input": "2025-02-14T16:56:06.200444Z",
          "iopub.status.idle": "2025-02-14T16:56:50.358305Z",
          "shell.execute_reply.started": "2025-02-14T16:56:06.200405Z",
          "shell.execute_reply": "2025-02-14T16:56:50.357529Z"
        },
        "id": "b7c55c2f-e0d0-4e5f-8acd-a7e034b74c8f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1f5dff31-f067-425c-b856-e9aab89de2fc",
      "cell_type": "markdown",
      "source": [
        "**Stacking Ensemble Implementation**"
      ],
      "metadata": {
        "id": "1f5dff31-f067-425c-b856-e9aab89de2fc"
      }
    },
    {
      "id": "04841cd4-dae4-4073-a095-16e2644b3e0c",
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Define meta-model (final classifier)\n",
        "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Define Stacking Classifier\n",
        "stacking_detection_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
        "stacking_class_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
        "\n",
        "# Fit models\n",
        "stacking_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "stacking_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Test labels\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Predictions\n",
        "detection_preds = stacking_detection_model.predict(detection_test_X)\n",
        "class_preds = stacking_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy\n",
        "print('Stacking Detection Model Accuracy:', stacking_detection_model.score(detection_test_X, detection_test_Y))\n",
        "print('Stacking Classification Model Accuracy:', stacking_class_model.score(class_test_X, class_Y_test))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:18:35.184629Z",
          "iopub.execute_input": "2025-02-14T15:18:35.184862Z",
          "iopub.status.idle": "2025-02-14T15:18:43.736851Z",
          "shell.execute_reply.started": "2025-02-14T15:18:35.184843Z",
          "shell.execute_reply": "2025-02-14T15:18:43.735898Z"
        },
        "id": "04841cd4-dae4-4073-a095-16e2644b3e0c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0727abce-a1a3-482a-a5dc-9c12e1854ee6",
      "cell_type": "markdown",
      "source": [
        "**Stacking HyperParameter Tuning**"
      ],
      "metadata": {
        "id": "0727abce-a1a3-482a-a5dc-9c12e1854ee6"
      }
    },
    {
      "id": "cfbdee6b-7bfc-4366-9eae-cc55de294209",
      "cell_type": "code",
      "source": [
        "# Convert y_train and y_test into 1D arrays (Fixes the error)\n",
        "detection_train_Y = detection_train_Y.values.ravel()\n",
        "detection_test_Y = detection_test_Y.values.ravel()\n",
        "\n",
        "class_train_Y = class_train_Y.values.ravel()\n",
        "class_test_Y = class_test_Y.values.ravel()\n",
        "\n",
        "# ===================== Hyperparameter Tuning: Detection Model ===================== #\n",
        "random_search_detection = RandomizedSearchCV(\n",
        "    stacking_detection_model, param_distributions=param_grid,\n",
        "    n_iter=5, cv=3, verbose=1, n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "random_search_detection.fit(detection_train_X, detection_train_Y)  # ✅ No more errors\n",
        "best_detection_model = random_search_detection.best_estimator_\n",
        "\n",
        "# ===================== Hyperparameter Tuning: Classification Model ===================== #\n",
        "random_search_classification = RandomizedSearchCV(\n",
        "    stacking_class_model, param_distributions=param_grid,\n",
        "    n_iter=5, cv=3, verbose=1, n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "random_search_classification.fit(class_train_X, class_train_Y)  # ✅ No more errors\n",
        "best_class_model = random_search_classification.best_estimator_\n",
        "\n",
        "# ===================== Model Predictions ===================== #\n",
        "detection_preds = best_detection_model.predict(detection_test_X)\n",
        "class_preds = best_class_model.predict(class_test_X)\n",
        "\n",
        "# ===================== Accuracy Scores ===================== #\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(class_test_Y, class_preds)\n",
        "\n",
        "# ===================== Classification Reports ===================== #\n",
        "print(\"========= Stacking Detection Model =========\")\n",
        "print(\"🔥 Detection Accuracy:\", detection_accuracy)\n",
        "print(\"\\nClassification Report for Detection Model:\")\n",
        "print(classification_report(detection_test_Y, detection_preds))\n",
        "\n",
        "print(\"\\n========= Stacking Classification Model =========\")\n",
        "print(\"🔥 Classification Accuracy:\", classification_accuracy)\n",
        "print(\"\\nClassification Report for Classification Model:\")\n",
        "print(classification_report(class_test_Y, class_preds))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:18:43.743740Z",
          "iopub.execute_input": "2025-02-14T15:18:43.744056Z",
          "iopub.status.idle": "2025-02-14T15:21:14.378095Z",
          "shell.execute_reply.started": "2025-02-14T15:18:43.744036Z",
          "shell.execute_reply": "2025-02-14T15:21:14.377106Z"
        },
        "id": "cfbdee6b-7bfc-4366-9eae-cc55de294209"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f0bd1474-60c9-43f2-8fa3-8edc3c821c25",
      "cell_type": "markdown",
      "source": [
        "**Graph of ensemble models**"
      ],
      "metadata": {
        "id": "f0bd1474-60c9-43f2-8fa3-8edc3c821c25"
      }
    },
    {
      "id": "9a21bf8b-b2e7-4900-af6e-dd87ce415a84",
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Accuracy values (Replace these with actual accuracy results from your models)\n",
        "models = [\"Bagging\", \"Gradient Boosting\", \"Random Forest\", \"Voting\", \"Stacking\"]\n",
        "detection_accuracies = [0.988, 0.985, 0.974, 0.974, 0.986]  # Example detection accuracies\n",
        "classification_accuracies = [0.805, 0.798, 0.777, 0.729, 0.867]  # Example classification accuracies\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(models))\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(index, detection_accuracies, bar_width, label=\"Detection Accuracy\", color=\"royalblue\")\n",
        "plt.bar(index + bar_width, classification_accuracies, bar_width, label=\"Classification Accuracy\", color=\"darkorange\")\n",
        "\n",
        "# Formatting the chart\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Comparison of Ensemble Models Based on Accuracy\")\n",
        "plt.xticks(index + bar_width / 2, models)\n",
        "plt.ylim(0.7, 1.0)  # Adjust based on your accuracy range\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:21:14.378878Z",
          "iopub.execute_input": "2025-02-14T15:21:14.379096Z",
          "iopub.status.idle": "2025-02-14T15:21:14.586830Z",
          "shell.execute_reply.started": "2025-02-14T15:21:14.379077Z",
          "shell.execute_reply": "2025-02-14T15:21:14.585936Z"
        },
        "id": "9a21bf8b-b2e7-4900-af6e-dd87ce415a84"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4193b844-3d5b-41ba-96e7-4087ac60bce7",
      "cell_type": "markdown",
      "source": [
        "**Cat Boost**"
      ],
      "metadata": {
        "id": "4193b844-3d5b-41ba-96e7-4087ac60bce7"
      }
    },
    {
      "id": "96c17682-a12a-474b-9cf5-e87841ec044c",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Optimized CatBoost Models\n",
        "cat_detection_model = CatBoostClassifier(iterations=3000, learning_rate=0.03, depth=8, random_state=42, verbose=500)\n",
        "cat_class_model = CatBoostClassifier(iterations=3000, learning_rate=0.03, depth=8, random_state=42, verbose=500)\n",
        "\n",
        "# Fit detection model\n",
        "cat_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "cat_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Create test labels correctly\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Predictions\n",
        "detection_preds = cat_detection_model.predict(detection_test_X)\n",
        "class_preds = cat_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy (Formatted Output)\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)\n",
        "print(\"CatBoost Classification Model Accuracy:\", round(cat_class_model.score(class_test_X, class_Y_test), 4))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "print(\"CatBoost Detection Model Accuracy:\", round(cat_detection_model.score(detection_test_X, detection_test_Y), 4))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:21:14.587475Z",
          "iopub.execute_input": "2025-02-14T15:21:14.587708Z",
          "iopub.status.idle": "2025-02-14T15:22:17.895818Z",
          "shell.execute_reply.started": "2025-02-14T15:21:14.587689Z",
          "shell.execute_reply": "2025-02-14T15:22:17.895062Z"
        },
        "id": "96c17682-a12a-474b-9cf5-e87841ec044c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e5e4eeaf-34f4-4825-8153-02bbb9d34531",
      "cell_type": "markdown",
      "source": [
        "**Cat Boost-HyperParameter Tuning**"
      ],
      "metadata": {
        "id": "e5e4eeaf-34f4-4825-8153-02bbb9d34531"
      }
    },
    {
      "id": "2f9f4bd8-730b-4494-ba3c-18161e2ee728",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ======= Step 1: Encode Labels =======\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(class_Y_train)\n",
        "Y_test_encoded = label_encoder.transform(class_Y_test)\n",
        "\n",
        "# ======= Step 2: Scale Features =======\n",
        "scaler = StandardScaler()\n",
        "class_train_X_scaled = scaler.fit_transform(class_train_X)\n",
        "class_test_X_scaled = scaler.transform(class_test_X)\n",
        "detection_train_X_scaled = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X_scaled = scaler.transform(detection_test_X)\n",
        "\n",
        "# ======= Step 3: Define Hyperparameter Grids =======\n",
        "param_grid_catboost = {\n",
        "    'iterations': [200, 500],          # Number of boosting iterations\n",
        "    'depth': [6, 10],                  # Tree depth\n",
        "    'learning_rate': [0.05, 0.1],       # Learning rate\n",
        "    'l2_leaf_reg': [3, 5],              # L2 regularization\n",
        "    'border_count': [32, 64],           # Splitting points in numerical features\n",
        "}\n",
        "\n",
        "# ======= Step 4: Train CatBoost Detection Model =======\n",
        "catboost_detection = CatBoostClassifier(task_type=\"CPU\", verbose=0, random_state=42)\n",
        "\n",
        "grid_search_detection = GridSearchCV(catboost_detection, param_grid_catboost, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_detection.fit(detection_train_X_scaled, detection_train_Y)\n",
        "\n",
        "best_catboost_detection = grid_search_detection.best_estimator_\n",
        "\n",
        "# ======= Step 5: Train CatBoost Classification Model =======\n",
        "catboost_classification = CatBoostClassifier(task_type=\"CPU\", verbose=0, random_state=42)\n",
        "\n",
        "grid_search_classification = GridSearchCV(catboost_classification, param_grid_catboost, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_classification.fit(class_train_X_scaled, Y_train_encoded)\n",
        "\n",
        "best_catboost_classification = grid_search_classification.best_estimator_\n",
        "\n",
        "# ======= Step 6: Evaluate Models =======\n",
        "detection_preds = best_catboost_detection.predict(detection_test_X_scaled)\n",
        "class_preds = best_catboost_classification.predict(class_test_X_scaled)\n",
        "\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(Y_test_encoded, class_preds)\n",
        "\n",
        "# ======= Step 7: Print Results =======\n",
        "print(f'CatBoost Detection Model Accuracy: {detection_accuracy:.4f}')\n",
        "print(f'CatBoost Classification Model Accuracy: {classification_accuracy:.4f}')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2f9f4bd8-730b-4494-ba3c-18161e2ee728"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4e800d2a-430b-4159-8858-9c571c3f6771",
      "cell_type": "markdown",
      "source": [
        "**Light GBM**"
      ],
      "metadata": {
        "id": "4e800d2a-430b-4159-8858-9c571c3f6771"
      }
    },
    {
      "id": "4e65c814-e558-4f76-b849-f8d0c3393ac3",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Optimized LightGBM Models\n",
        "lgb_detection_model = lgb.LGBMClassifier(n_estimators=3000, learning_rate=0.03, max_depth=10, random_state=42, verbose=-1)\n",
        "lgb_class_model = lgb.LGBMClassifier(n_estimators=3000, learning_rate=0.03, max_depth=10, random_state=42, verbose=-1)\n",
        "\n",
        "# Fit detection model\n",
        "lgb_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# Encode multi-class labels properly (for training)\n",
        "class_Y_train = (class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                 class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel()\n",
        "\n",
        "# Fit classification model\n",
        "lgb_class_model.fit(class_train_X, class_Y_train)\n",
        "\n",
        "# Create test labels correctly\n",
        "class_Y_test = (class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel()\n",
        "\n",
        "# Predictions\n",
        "detection_preds = lgb_detection_model.predict(detection_test_X)\n",
        "class_preds = lgb_class_model.predict(class_test_X)\n",
        "\n",
        "# Printing Accuracy (Formatted Output)\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test.shape)\n",
        "print(\"LightGBM Classification Model Accuracy:\", round(lgb_class_model.score(class_test_X, class_Y_test), 4))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "print(\"LightGBM Detection Model Accuracy:\", round(lgb_detection_model.score(detection_test_X, detection_test_Y), 4))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:22:17.896631Z",
          "iopub.execute_input": "2025-02-14T15:22:17.896924Z",
          "iopub.status.idle": "2025-02-14T15:22:37.147393Z",
          "shell.execute_reply.started": "2025-02-14T15:22:17.896896Z",
          "shell.execute_reply": "2025-02-14T15:22:37.146392Z"
        },
        "id": "4e65c814-e558-4f76-b849-f8d0c3393ac3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "377d0629-ec66-4510-910d-3ac12eebfce4",
      "cell_type": "markdown",
      "source": [
        "**Light GBM- Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "377d0629-ec66-4510-910d-3ac12eebfce4"
      }
    },
    {
      "id": "931dc36b-3c5d-4907-9d9c-7ebbc4bbf2ed",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ======= Step 1: Encode Labels =======\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(class_Y_train)\n",
        "Y_test_encoded = label_encoder.transform(class_Y_test)\n",
        "\n",
        "# ======= Step 2: Scale Features =======\n",
        "scaler = StandardScaler()\n",
        "class_train_X_scaled = scaler.fit_transform(class_train_X)\n",
        "class_test_X_scaled = scaler.transform(class_test_X)\n",
        "detection_train_X_scaled = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X_scaled = scaler.transform(detection_test_X)\n",
        "\n",
        "# ======= Step 3: Define Hyperparameter Grids =======\n",
        "param_grid_lgbm = {\n",
        "    'n_estimators': [200, 500],          # Number of boosting iterations\n",
        "    'learning_rate': [0.05, 0.1],        # Learning rate\n",
        "    'max_depth': [6, 10],                # Max depth of trees\n",
        "    'num_leaves': [31, 50],              # Number of leaves in trees\n",
        "    'reg_alpha': [0.1, 0.5],             # L1 regularization\n",
        "    'reg_lambda': [0.1, 0.5],            # L2 regularization\n",
        "}\n",
        "\n",
        "# ======= Step 4: Train LightGBM Detection Model =======\n",
        "lgbm_detection = lgb.LGBMClassifier(objective='binary', random_state=42)\n",
        "\n",
        "grid_search_detection = GridSearchCV(lgbm_detection, param_grid_lgbm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_detection.fit(detection_train_X_scaled, detection_train_Y)\n",
        "\n",
        "best_lgbm_detection = grid_search_detection.best_estimator_\n",
        "\n",
        "# ======= Step 5: Train LightGBM Classification Model =======\n",
        "lgbm_classification = lgb.LGBMClassifier(objective='multiclass', num_class=len(np.unique(Y_train_encoded)), random_state=42)\n",
        "\n",
        "grid_search_classification = GridSearchCV(lgbm_classification, param_grid_lgbm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_classification.fit(class_train_X_scaled, Y_train_encoded)\n",
        "\n",
        "best_lgbm_classification = grid_search_classification.best_estimator_\n",
        "\n",
        "# ======= Step 6: Evaluate Models =======\n",
        "detection_preds = best_lgbm_detection.predict(detection_test_X_scaled)\n",
        "class_preds = best_lgbm_classification.predict(class_test_X_scaled)\n",
        "\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(Y_test_encoded, class_preds)\n",
        "\n",
        "# ======= Step 7: Print Results =======\n",
        "print(f'LightGBM Detection Model Accuracy: {detection_accuracy:.4f}')\n",
        "print(f'LightGBM Classification Model Accuracy: {classification_accuracy:.4f}')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "931dc36b-3c5d-4907-9d9c-7ebbc4bbf2ed"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "516ed8aa-0bbb-4301-b84c-a5cbd164072f",
      "cell_type": "markdown",
      "source": [
        "**XG Boost**"
      ],
      "metadata": {
        "id": "516ed8aa-0bbb-4301-b84c-a5cbd164072f"
      }
    },
    {
      "id": "cecee89f-b130-4f4f-828f-af52bf7f062e",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Encode detection labels (binary classification)\n",
        "xgb_detection_model = xgb.XGBClassifier(n_estimators=3000, learning_rate=0.03, max_depth=10,\n",
        "                                        subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0)\n",
        "xgb_detection_model.fit(detection_train_X, detection_train_Y)\n",
        "\n",
        "# **Fix Multi-Class Labels for Classification**\n",
        "# Step 1: Create a LabelEncoder to map unique labels to continuous numbers\n",
        "label_encoder = LabelEncoder()\n",
        "class_Y_train_encoded = label_encoder.fit_transform((class_train_Y['G']*1 + class_train_Y['A']*2 +\n",
        "                                                     class_train_Y['B']*3 + class_train_Y['C']*5).values.ravel())\n",
        "class_Y_test_encoded = label_encoder.transform((class_test_Y['G']*1 + class_test_Y['A']*2 +\n",
        "                                                class_test_Y['B']*3 + class_test_Y['C']*5).values.ravel())\n",
        "\n",
        "# Step 2: Train XGBoost Classification Model\n",
        "xgb_class_model = xgb.XGBClassifier(n_estimators=3000, learning_rate=0.03, max_depth=10,\n",
        "                                    subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0)\n",
        "xgb_class_model.fit(class_train_X, class_Y_train_encoded)\n",
        "\n",
        "# Step 3: Predictions\n",
        "detection_preds = xgb_detection_model.predict(detection_test_X)\n",
        "class_preds_encoded = xgb_class_model.predict(class_test_X)\n",
        "\n",
        "# Step 4: Convert predictions back to original labels\n",
        "class_preds = label_encoder.inverse_transform(class_preds_encoded)\n",
        "\n",
        "# **Print Accuracy**\n",
        "print(\"Class Test X Shape:\", class_test_X.shape)\n",
        "print(\"Class Y Test Shape:\", class_Y_test_encoded.shape)\n",
        "print(\"XGBoost Classification Model Accuracy:\", round(xgb_class_model.score(class_test_X, class_Y_test_encoded), 4))\n",
        "\n",
        "print(\"Detection Test X Shape:\", detection_test_X.shape)\n",
        "print(\"Detection Test Y Shape:\", detection_test_Y.shape)\n",
        "print(\"XGBoost Detection Model Accuracy:\", round(xgb_detection_model.score(detection_test_X, detection_test_Y), 4))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:22:37.148376Z",
          "iopub.execute_input": "2025-02-14T15:22:37.149105Z",
          "iopub.status.idle": "2025-02-14T15:22:55.576014Z",
          "shell.execute_reply.started": "2025-02-14T15:22:37.149076Z",
          "shell.execute_reply": "2025-02-14T15:22:55.575273Z"
        },
        "id": "cecee89f-b130-4f4f-828f-af52bf7f062e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d32ee545-fd31-4543-b6a7-54aeba7cdd05",
      "cell_type": "markdown",
      "source": [
        "\n",
        "**XG Boost- hyperparameter tuning**"
      ],
      "metadata": {
        "id": "d32ee545-fd31-4543-b6a7-54aeba7cdd05"
      }
    },
    {
      "id": "6359fcbc-29fe-4ee2-99bf-f9e3de6560b8",
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming detection_train_X, detection_train_Y, class_train_X, and class_Y_train are already defined\n",
        "\n",
        "# Step 1: Encode class labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(class_Y_train)\n",
        "Y_test_encoded = label_encoder.transform(class_Y_test)\n",
        "\n",
        "# Step 2: Preprocessing the feature data (scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "class_train_X_scaled = scaler.fit_transform(class_train_X)\n",
        "class_test_X_scaled = scaler.transform(class_test_X)\n",
        "\n",
        "# Split detection data (similar to class data)\n",
        "detection_train_X_scaled = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X_scaled = scaler.transform(detection_test_X)\n",
        "\n",
        "# Step 3: Model Definition with Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=6, random_state=42)\n",
        "\n",
        "# Step 4: Hyperparameter tuning using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(class_train_X_scaled, Y_train_encoded)\n",
        "\n",
        "# Best model from GridSearchCV\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Step 5: Evaluate Model on Test Set\n",
        "class_preds = best_xgb_model.predict(class_test_X_scaled)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "classification_accuracy = accuracy_score(Y_test_encoded, class_preds)\n",
        "print(f'XGBoost Classification Model Accuracy: {classification_accuracy}')\n",
        "\n",
        "# Step 6: Train the Detection Model (XGBoost for binary classification)\n",
        "detection_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "detection_model.fit(detection_train_X_scaled, detection_train_Y)\n",
        "\n",
        "# Step 7: Evaluate Detection Model\n",
        "detection_preds = detection_model.predict(detection_test_X_scaled)\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "print(f'XGBoost Detection Model Accuracy: {detection_accuracy}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:22:55.577041Z",
          "iopub.execute_input": "2025-02-14T15:22:55.577434Z",
          "iopub.status.idle": "2025-02-14T15:31:06.195987Z",
          "shell.execute_reply.started": "2025-02-14T15:22:55.577410Z",
          "shell.execute_reply": "2025-02-14T15:31:06.194860Z"
        },
        "id": "6359fcbc-29fe-4ee2-99bf-f9e3de6560b8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ece71635-9457-4d8d-a022-447585a0cf2b",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ======= Step 1: Encode Labels =======\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(class_Y_train)\n",
        "Y_test_encoded = label_encoder.transform(class_Y_test)\n",
        "\n",
        "# ======= Step 2: Scale Features =======\n",
        "scaler = StandardScaler()\n",
        "class_train_X_scaled = scaler.fit_transform(class_train_X)\n",
        "class_test_X_scaled = scaler.transform(class_test_X)\n",
        "detection_train_X_scaled = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X_scaled = scaler.transform(detection_test_X)\n",
        "\n",
        "# ======= Step 3: Define Hyperparameter Grids =======\n",
        "param_grid_catboost = {\n",
        "    'iterations': [200, 500],          # Number of boosting iterations\n",
        "    'depth': [6, 10],                  # Tree depth\n",
        "    'learning_rate': [0.05, 0.1],       # Learning rate\n",
        "    'l2_leaf_reg': [3, 5],              # L2 regularization\n",
        "    'border_count': [32, 64],           # Splitting points in numerical features\n",
        "}\n",
        "\n",
        "# ======= Step 4: Train CatBoost Detection Model =======\n",
        "catboost_detection = CatBoostClassifier(task_type=\"CPU\", verbose=0, random_state=42)\n",
        "\n",
        "grid_search_detection = GridSearchCV(catboost_detection, param_grid_catboost, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_detection.fit(detection_train_X_scaled, detection_train_Y)\n",
        "\n",
        "best_catboost_detection = grid_search_detection.best_estimator_\n",
        "\n",
        "# ======= Step 5: Train CatBoost Classification Model =======\n",
        "catboost_classification = CatBoostClassifier(task_type=\"CPU\", verbose=0, random_state=42)\n",
        "\n",
        "grid_search_classification = GridSearchCV(catboost_classification, param_grid_catboost, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_classification.fit(class_train_X_scaled, Y_train_encoded)\n",
        "\n",
        "best_catboost_classification = grid_search_classification.best_estimator_\n",
        "\n",
        "# ======= Step 6: Evaluate Models =======\n",
        "detection_preds = best_catboost_detection.predict(detection_test_X_scaled)\n",
        "class_preds = best_catboost_classification.predict(class_test_X_scaled)\n",
        "\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(Y_test_encoded, class_preds)\n",
        "\n",
        "# ======= Step 7: Print Results =======\n",
        "print(f'CatBoost Detection Model Accuracy: {detection_accuracy:.4f}')\n",
        "print(f'CatBoost Classification Model Accuracy: {classification_accuracy:.4f}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:31:06.196815Z",
          "iopub.execute_input": "2025-02-14T15:31:06.197092Z",
          "iopub.status.idle": "2025-02-14T15:37:17.214633Z",
          "shell.execute_reply.started": "2025-02-14T15:31:06.197069Z",
          "shell.execute_reply": "2025-02-14T15:37:17.213557Z"
        },
        "id": "ece71635-9457-4d8d-a022-447585a0cf2b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0c58a6c4-0c70-4cef-bb7a-6bab78317efb",
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ======= Step 1: Encode Labels =======\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train_encoded = label_encoder.fit_transform(class_Y_train)\n",
        "Y_test_encoded = label_encoder.transform(class_Y_test)\n",
        "\n",
        "# ======= Step 2: Scale Features =======\n",
        "scaler = StandardScaler()\n",
        "class_train_X_scaled = scaler.fit_transform(class_train_X)\n",
        "class_test_X_scaled = scaler.transform(class_test_X)\n",
        "detection_train_X_scaled = scaler.fit_transform(detection_train_X)\n",
        "detection_test_X_scaled = scaler.transform(detection_test_X)\n",
        "\n",
        "# ======= Step 3: Define Hyperparameter Grids =======\n",
        "param_grid_lgbm = {\n",
        "    'n_estimators': [200, 500],          # Number of boosting iterations\n",
        "    'learning_rate': [0.05, 0.1],        # Learning rate\n",
        "    'max_depth': [6, 10],                # Max depth of trees\n",
        "    'num_leaves': [31, 50],              # Number of leaves in trees\n",
        "    'reg_alpha': [0.1, 0.5],             # L1 regularization\n",
        "    'reg_lambda': [0.1, 0.5],            # L2 regularization\n",
        "}\n",
        "\n",
        "# ======= Step 4: Train LightGBM Detection Model =======\n",
        "lgbm_detection = lgb.LGBMClassifier(objective='binary', random_state=42)\n",
        "\n",
        "grid_search_detection = GridSearchCV(lgbm_detection, param_grid_lgbm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_detection.fit(detection_train_X_scaled, detection_train_Y)\n",
        "\n",
        "best_lgbm_detection = grid_search_detection.best_estimator_\n",
        "\n",
        "# ======= Step 5: Train LightGBM Classification Model =======\n",
        "lgbm_classification = lgb.LGBMClassifier(objective='multiclass', num_class=len(np.unique(Y_train_encoded)), random_state=42)\n",
        "\n",
        "grid_search_classification = GridSearchCV(lgbm_classification, param_grid_lgbm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_classification.fit(class_train_X_scaled, Y_train_encoded)\n",
        "\n",
        "best_lgbm_classification = grid_search_classification.best_estimator_\n",
        "\n",
        "# ======= Step 6: Evaluate Models =======\n",
        "detection_preds = best_lgbm_detection.predict(detection_test_X_scaled)\n",
        "class_preds = best_lgbm_classification.predict(class_test_X_scaled)\n",
        "\n",
        "detection_accuracy = accuracy_score(detection_test_Y, detection_preds)\n",
        "classification_accuracy = accuracy_score(Y_test_encoded, class_preds)\n",
        "\n",
        "# ======= Step 7: Print Results =======\n",
        "print(f'LightGBM Detection Model Accuracy: {detection_accuracy:.4f}')\n",
        "print(f'LightGBM Classification Model Accuracy: {classification_accuracy:.4f}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-14T15:37:17.215799Z",
          "iopub.execute_input": "2025-02-14T15:37:17.216070Z",
          "iopub.status.idle": "2025-02-14T15:43:29.483021Z",
          "shell.execute_reply.started": "2025-02-14T15:37:17.216048Z",
          "shell.execute_reply": "2025-02-14T15:43:29.481552Z"
        },
        "id": "0c58a6c4-0c70-4cef-bb7a-6bab78317efb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}